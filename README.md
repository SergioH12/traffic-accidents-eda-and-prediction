# TP1 ‚Äî An√°lisis del dataset "Accidente"

Resumen
-------
Este repositorio contiene el trabajo pr√°ctico TP1: an√°lisis exploratorio y modelado del dataset "Accidente" (accidents). El an√°lisis principal est√° en el notebook `TP1_Accidente.ipynb`. El objetivo es explorar las caracter√≠sticas del dataset, realizar limpieza y transformaciones relevantes, y construir modelos de clasificaci√≥n para predecir la severidad (`Severity`) del accidente.

Enlaces relevantes
------------------
- Notebook principal: https://github.com/SergioH12/Analisis1/blob/f2a8da17c66b8c7827baeb070bf43edb0296e52b/TP1_Accidente.ipynb
- Archivo de datos esperado: `Accidente.csv`
## üì• Descargar dataset (1 GB)

El dataset completo est√° disponible para su descarga directa en el siguiente enlace:

‚û°Ô∏è **[Descargar dataset](https://drive.google.com/uc?export=download&id=1wUXbETeZ2kZRKgmGZzm1XDZn1VKvLGMo)**


Descripci√≥n del dataset
-----------------------
Cada fila representa un evento de accidente vial y las columnas contienen atributos del evento. Algunas columnas clave:
- Source, TMC, Severity (1‚Äì4), Start_Time, End_Time, Start_Lat, Start_Lng
- Weather_Timestamp, Temperature(F), Wind_Chill(F), Humidity(%), Pressure(in), Visibility(mi)
- Wind_Direction, Wind_Speed(mph), Precipitation(in), Weather_Condition
- Variables booleanas de POIs (Amenity, Bump, Crossing, ...), y columnas sobre crep√∫sculo / amanecer ('Sunrise_Sunset', 'Civil_Twilight', ...)

Cantidad de datos (aprox.)
- ~2.97M filas y 49 columnas en el dataset original.

Contenido del repositorio
-------------------------
- TP1_Accidente.ipynb ‚Äî Notebook con todo el flujo de an√°lisis: carga de datos, limpieza, EDA y modelado (PyCaret).
- Accidente.csv ‚Äî CSV con los datos (si est√° presente en el repo).
- README.md ‚Äî (este archivo).

Requisitos / Dependencias
-------------------------
El notebook se desarroll√≥ usando Python 3.x y las siguientes librer√≠as (no exhaustiva):
- pandas
- numpy
- matplotlib
- scikit-learn
- pycaret
- jupyter

Puedes crear un entorno virtual e instalar dependencias con pip:
```text
pandas
numpy
matplotlib
scikit-learn
pycaret
jupyter
```

Instalaci√≥n r√°pida (ejemplo usando virtualenv + pip)
```bash
# crear y activar entorno (Linux / macOS)
python3 -m venv .venv
source .venv/bin/activate

# Windows (PowerShell)
# python -m venv .venv
# .\.venv\Scripts\Activate.ps1

pip install --upgrade pip
pip install -r requirements.txt
```

C√≥mo ejecutar
-------------
1. Aseg√∫rate de tener `Accidente.csv` en la ruta correcta (la ruta por defecto utilizada en el notebook es `./Accidente.csv`).
2. Inicia Jupyter Notebook:
```bash
jupyter notebook
```
3. Abre `TP1_Accidente.ipynb` y ejecuta las celdas en orden.

Si prefieres ejecutar en Google Colab:
- Sube `Accidente.csv` al entorno de Colab o monta Google Drive y ajusta la ruta en el notebook.

Resumen del flujo del notebook
------------------------------
1. Carga de datos con pandas y examen inicial (`.info()`, `.head()`, `.describe()`).
2. Eliminaci√≥n de columnas irrelevantes y manejo de nulos/duplicados.
3. Conversi√≥n de columnas de fecha/hora, extracci√≥n de variables temporales (hora, d√≠a, etc.).
4. An√°lisis exploratorio (distribuciones, correlaciones, conteos por `Severity`, visualizaciones).
5. Preprocesamiento: codificaci√≥n de variables categ√≥ricas, escalado si corresponde, tratamiento de outliers.
6. Modelado: uso de PyCaret para experimentaci√≥n con clasificadores y selecci√≥n de modelos.
7. Evaluaci√≥n y conclusiones.

Buenas pr√°cticas y notas
------------------------
- El dataset es grande (~3M filas): ten en cuenta memoria al cargarlo en m√°quinas con recursos limitados. Considera muestrear o trabajar por lotes si hace falta.
- Guarda versiones del notebook y usa checkpoints al experimentar con modelos pesados.
- Cuando uses PyCaret, revisa la configuraci√≥n del `setup()` para controlar imputaci√≥n, codificaci√≥n y muestreo.

Resultados y conclusiones (resumen)
-----------------------------------
Dentro del notebook se documentan los hallazgos principales (distribuci√≥n de severidad, relaciones con condiciones clim√°ticas, hora del d√≠a, y otras variables). Las conclusiones sobre la capacidad predictiva de las caracter√≠sticas y el desempe√±o de los modelos est√°n en la secci√≥n final del notebook.


Contacto
--------
Autor: SergioH12  
Repositorio: https://github.com/SergioH12/Analisis1

```
